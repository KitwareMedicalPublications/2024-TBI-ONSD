{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d5887-9196-4a1c-a0c2-f43627713c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Notebook to demonstrate the augmentations done in the\n",
    "compare_augmentations.ipynb notebook. Creates a\n",
    "dataloader with 1 batch of images, then transforms each\n",
    "of the images in the batch. Saves the result to\n",
    "check_augmentations_dir/screenshots.\n",
    "'''\n",
    "\n",
    "\n",
    "import tbitk.ai.deep_learning as dl\n",
    "import matplotlib.pyplot as plt\n",
    "import itk\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from monai.transforms import (\n",
    "    RandRotated,\n",
    "    RandScaleIntensityd,\n",
    "    ThresholdIntensityd,\n",
    "    RandAffined,\n",
    "    LoadImaged,\n",
    "    EnsureTyped,\n",
    "    AddChanneld,\n",
    "    Resized,\n",
    "    ScaleIntensityd,\n",
    "    RandFlipd,\n",
    "    Compose,\n",
    "    MapTransform\n",
    ")\n",
    "from tbitk.ai.transforms import eval_transforms, eval_transforms\n",
    "from tbitk.ai.constants import DEFAULT_BEST_MODEL_NAME, BATCH_SIZE\n",
    "from torchvision.utils import make_grid\n",
    "NETWORK_INPUT_SHAPE = (256, 256)\n",
    "def get_transforms(l):\n",
    "    transforms = [\n",
    "        LoadImaged(keys=[\"x\", \"y\"], image_only=True),\n",
    "        EnsureTyped(keys=[\"x\", \"y\"]),\n",
    "        AddChanneld(keys=[\"x\", \"y\"]),\n",
    "        Resized(keys=[\"x\", \"y\"], spatial_size=NETWORK_INPUT_SHAPE, mode=\"nearest\"),\n",
    "    ]\n",
    "    if \"gain\" in l:\n",
    "        transforms.append(RandScaleIntensityd(keys=[\"x\"], prob=1, factors=(0, 0.75)))\n",
    "        transforms.append(ThresholdIntensityd(keys=[\"x\"], threshold=1, above=False, cval=1))\n",
    "    if \"randflip\" in l:\n",
    "        transforms.append(RandFlipd(keys=[\"x\", \"y\"], prob=1, spatial_axis=1))\n",
    "    if \"randtranslate\" in l:\n",
    "        transforms.append(RandAffined(keys=[\"x\", \"y\"], prob=1, translate_range=(0, 50), padding_mode=\"zeros\"))\n",
    "    if \"randrotate\" in l:\n",
    "        transforms.append(RandRotated(keys=[\"x\", \"y\"], prob=1, range_x=0.35, padding_mode=\"zeros\"))\n",
    "        \n",
    "    transforms.extend([\n",
    "        EnsureTyped(keys=[\"x\"], data_type=\"numpy\"),\n",
    "#         ScaleIntensityd(keys=[\"x\"]),\n",
    "        EnsureTyped(keys=[\"x\", \"y\"])\n",
    "    ])\n",
    "\n",
    "    return Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6109123-6d84-4e2b-afe9-c8cf3dc56b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This needs to be a directory containing extracted frames\n",
    "# and masks. Naming convention should be img_{i}.mha and mask_{i}.mha\n",
    "# for the entire directory.\n",
    "# Here we use the extracted files from a run of the main notebook\n",
    "INPUT_DATA_DIR = Path(\"051622/data/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3ab92f-e424-4106-9418-ddb59d4a97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write them to a directory\n",
    "check_augs_dir = Path(\"check_augmentations_dir/\")\n",
    "ex_images_dir = check_augs_dir / \"ex_images\"\n",
    "screenshot_dir = check_augs_dir / \"screenshots\"\n",
    "\n",
    "ex_images_dir.mkdir(exist_ok=True, parents=True)\n",
    "screenshot_dir.mkdir(exist_ok=True, parents=True)\n",
    "for i in range(BATCH_SIZE):\n",
    "    im = itk.imread(str(INPUT_DATA_DIR / f\"img_{i}.mha\"))\n",
    "    mask = itk.imread(str(INPUT_DATA_DIR / f\"mask_{i}.mha\"))\n",
    "\n",
    "    itk.imwrite(im, str(ex_images_dir / f\"img_{i}.mha\"))\n",
    "    itk.imwrite(mask, str(ex_images_dir / f\"mask_{i}.mha\"))\n",
    "\n",
    "def save_transformed_batch(transform, fname, dir_=ex_images_dir):\n",
    "    data_loader = dl.get_data_loader([dir_], transform, shuffle=False)\n",
    "    batchdata = next(iter(data_loader))\n",
    "    grid = make_grid(batchdata[\"x\"], nrow=4)\n",
    "    grid = grid[0]\n",
    "    plt.imsave(screenshot_dir / fname, grid)\n",
    "    \n",
    "\n",
    "save_transformed_batch(get_transforms([]), \"no_aug.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147449c-9019-4b77-b740-722c2ecce2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transforms([\"gain\"])\n",
    "save_transformed_batch(transform, \"gain.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068032b-2ad5-43ae-bc61-a7bcfc9c5a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transforms([\"randtranslate\"])\n",
    "save_transformed_batch(transform, \"translate.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93794f73-c573-41fd-84f7-000def6d7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transforms(\"randrotate\")\n",
    "save_transformed_batch(transform, \"rotate.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tbi_env",
   "language": "python",
   "name": "tbi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
