{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862d7c3a-4959-4645-b7d2-a3d42cd1df41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: more-itertools in /home/tom.osika/ultrasound_tbi/med_env/lib/python3.8/site-packages (8.13.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/home/tom.osika/ultrasound_tbi/med_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install more-itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f1f77a-3940-44af-8455-fc9865e56f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n"
     ]
    }
   ],
   "source": [
    "import tbitk.ai.deep_learning as dl\n",
    "import tbitk.ai.dl_cli as dl_cli\n",
    "import more_itertools\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "from pathlib import Path\n",
    "from monai.transforms import (\n",
    "    RandRotated,\n",
    "    RandScaleIntensityd,\n",
    "    ThresholdIntensityd,\n",
    "    RandAffined,\n",
    "    LoadImaged,\n",
    "    EnsureTyped,\n",
    "    AddChanneld,\n",
    "    Resized,\n",
    "    ScaleIntensityd,\n",
    "    RandFlipd,\n",
    "    Compose,\n",
    "    MapTransform\n",
    ")\n",
    "from tbitk.ai.transforms import eval_transforms, eval_transforms\n",
    "from tbitk.ai.constants import DEFAULT_BEST_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e492db69-d389-4be3-98da-f389f66e0fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATA_DIR = Path(\"../../data/\")\n",
    "\n",
    "file_patterns = []\n",
    "file_patterns.append(str((ALL_DATA_DIR / \"HRPO-E01240.1a/preprocessed/ONUS-00[12]HV/butterfly-iq/**/*.mha\").resolve()))\n",
    "file_patterns.append(str((ALL_DATA_DIR / \"training_head_phantom-20220121/preprocessed/butterfly-iq/[AB]/**/*.mha\").resolve()))\n",
    "file_patterns.append(str((ALL_DATA_DIR / \"training_head_phantom-20220121/preprocessed/butterfly-iq/E/e-[12].mha\").resolve()))\n",
    "\n",
    "NEED_TO_EXTRACT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33955372-c39e-438f-aafa-b64791cc35cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NEED_TO_EXTRACT:\n",
    "    # Extract the data\n",
    "    extract_cmd = [\"extract\"]\n",
    "\n",
    "    extract_cmd.append(\"--root_dir\")\n",
    "    extract_cmd.append(str(Path(\"data/\").resolve()))\n",
    "\n",
    "    extract_cmd.append(\"--file_patterns\")\n",
    "    for fp in file_patterns:\n",
    "        extract_cmd.append(fp)\n",
    "\n",
    "    extract_cmd.append(\"--print_found_files\")\n",
    "    \n",
    "    dl_cli.main(extract_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1fe0b16-19e3-427b-9f2e-8bf7f5af9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintTransform(MapTransform):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        print(data)\n",
    "        return data\n",
    "\n",
    "NETWORK_INPUT_SHAPE = (256, 256)\n",
    "def get_transforms(l):\n",
    "    transforms = [\n",
    "        LoadImaged(keys=[\"x\", \"y\"], image_only=True),\n",
    "        EnsureTyped(keys=[\"x\", \"y\"]),\n",
    "        AddChanneld(keys=[\"x\", \"y\"]),\n",
    "        Resized(keys=[\"x\", \"y\"], spatial_size=NETWORK_INPUT_SHAPE, mode=\"nearest\"),\n",
    "    ]\n",
    "    if \"gain\" in l:\n",
    "        transforms.append(RandScaleIntensityd(keys=[\"x\"], prob=0.5, factors=(0, 0.75)))\n",
    "        transforms.append(ThresholdIntensityd(keys=[\"x\"], threshold=1, above=False, cval=1))\n",
    "    if \"randflip\" in l:\n",
    "        transforms.append(RandFlipd(keys=[\"x\", \"y\"], prob=0.5, spatial_axis=1))\n",
    "    if \"randtranslate\" in l:\n",
    "        transforms.append(RandAffined(keys=[\"x\", \"y\"], prob=0.5, translate_range=(0, 50), padding_mode=\"zeros\"))\n",
    "    if \"randrotate\" in l:\n",
    "        transforms.append(RandRotated(keys=[\"x\", \"y\"], prob=0.5, range_x=0.35, padding_mode=\"zeros\"))\n",
    "        \n",
    "    transforms.extend([\n",
    "        EnsureTyped(keys=[\"x\"], data_type=\"numpy\"),\n",
    "        ScaleIntensityd(keys=[\"x\"]),\n",
    "        EnsureTyped(keys=[\"x\", \"y\"])\n",
    "    ])\n",
    "\n",
    "    return Compose(transforms)\n",
    "\n",
    "\n",
    "augmentation_names = [\"gain\", \"randflip\", \"randtranslate\", \"randrotate\"]\n",
    "combos = list(more_itertools.powerset(augmentation_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6867d231-8b0a-4f6d-b7e6-b077be8147ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9586665034294128\n",
      "###### no_aug.pt: 0.9586665034294128 + ######\n",
      "0.956766664981842\n",
      "###### gain.pt: 0.956766664981842 + ######\n",
      "0.9400314092636108\n",
      "###### randflip.pt: 0.9400314092636108 + ######\n",
      "0.9489437341690063\n",
      "###### randtranslate.pt: 0.9489437341690063 + ######\n",
      "0.9391183257102966\n",
      "###### randrotate.pt: 0.9391183257102966 + ######\n",
      "0.9442896246910095\n",
      "###### gainrandflip.pt: 0.9442896246910095 + ######\n",
      "0.9435879588127136\n",
      "###### gainrandtranslate.pt: 0.9435879588127136 + ######\n",
      "0.9424556493759155\n",
      "###### gainrandrotate.pt: 0.9424556493759155 + ######\n",
      "0.9363917708396912\n",
      "###### randfliprandtranslate.pt: 0.9363917708396912 + ######\n",
      "0.931233823299408\n",
      "###### randfliprandrotate.pt: 0.931233823299408 + ######\n",
      "0.9301144480705261\n",
      "###### randtranslaterandrotate.pt: 0.9301144480705261 + ######\n",
      "0.932685375213623\n",
      "###### gainrandfliprandtranslate.pt: 0.932685375213623 + ######\n",
      "0.9157265424728394\n",
      "###### gainrandfliprandrotate.pt: 0.9157265424728394 + ######\n",
      "0.9287465214729309\n",
      "###### gainrandtranslaterandrotate.pt: 0.9287465214729309 + ######\n",
      "0.9150715470314026\n",
      "###### randfliprandtranslaterandrotate.pt: 0.9150715470314026 + ######\n",
      "0.9119986891746521\n",
      "###### gainrandfliprandtranslaterandrotate.pt: 0.9119986891746521 + ######\n"
     ]
    }
   ],
   "source": [
    "model_name_to_dice = {}\n",
    "LOG_TO_FILE = True\n",
    "for combo in combos:\n",
    "    transforms = get_transforms(combo)\n",
    "    \n",
    "    model = dl.get_model()\n",
    "    \n",
    "    train_dir = Path(\"data/train\").resolve()\n",
    "    val_dir = Path(\"data/val\").resolve()\n",
    "    train_loader = dl.get_data_loader([str(train_dir)], transforms)\n",
    "    val_loader = dl.get_data_loader([str(val_dir)], dl.eval_transforms)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logfile = train_dir / \"log.txt\"\n",
    "    \n",
    "    if LOG_TO_FILE:\n",
    "        with open(str(logfile), \"a+\") as f:\n",
    "            f.write(f\"###### {combo} ######\\n\")\n",
    "    else:\n",
    "        print(combo)\n",
    "\n",
    "    # TODO: below\n",
    "#     for _ in range(1):\n",
    "#         batch = next(iter(train_loader))\n",
    "#     plt.imshow(torchvision.utils.make_grid(batch[\"x\"]).permute(1, 2, 0)); plt.show()\n",
    "#     plt.imshow(torchvision.utils.make_grid(batch[\"y\"]).permute(1, 2, 0)); plt.show()\n",
    "    combo_tb_experiment_subdir = \"\".join(combo)\n",
    "    if len(combo_tb_experiment_subdir) == 0:\n",
    "        combo_tb_experiment_subdir = \"no_aug\"\n",
    "    combo_tb_experiment_subdir = Path(\"runs\") / combo_tb_experiment_subdir\n",
    "    \n",
    "    model_name = \"\".join(combo)\n",
    "    if len(model_name) == 0:\n",
    "        model_name = \"no_aug\"\n",
    "    \n",
    "    model_name += \".pt\"\n",
    "        \n",
    "    dl.train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        device,\n",
    "        model_name,\n",
    "        Path(\"models/\").resolve(),\n",
    "        monitor_with_tb=True,\n",
    "        tb_logdir=combo_tb_experiment_subdir,\n",
    "        status_logfile=logfile,\n",
    "        num_epochs=40\n",
    "    )\n",
    "    \n",
    "    best_model = dl.load_model(Path(\"models\").resolve() / model_name)\n",
    "    test_dir = Path(\"data/test\").resolve()\n",
    "    test_loader = dl.get_data_loader(\n",
    "            [str(test_dir)], eval_transforms\n",
    "    )\n",
    "    test_dice = dl.test_model(best_model, test_loader, device)\n",
    "    model_name_to_dice[model_name] = test_dice\n",
    "    s = f\"###### {model_name}: {test_dice} ######\"\n",
    "    if LOG_TO_FILE:\n",
    "        with open(str(logfile), \"a+\") as f:\n",
    "            f.write(s + \"\\n\")\n",
    "    print(s)\n",
    "    \n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "with open(\"results.p\", \"wb\") as f:\n",
    "    pickle.dump(model_name_to_dice, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tbi_env",
   "language": "python",
   "name": "tbi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
